<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <title>Research Journal</title>

        <link rel="stylesheet" href="css/main.css" type="text/css" media="all">

        <!-- typeplate -->
        <link rel="stylesheet" href="css/typeplate.css" type="text/css" media="all">

        <!-- MathJax -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                extensions: ["tex2jax.js"],
                jax: ["input/TeX", "output/HTML-CSS"],
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true
                },
                "HTML-CSS": { availableFonts: ["TeX"] }
            });
        </script>
        <script type="text/javascript" src="js/MathJax/MathJax.js"></script>

        <!-- Highlight.js -->
        <link rel="stylesheet" href="js/Highlight.js/styles/default.css">
        <script src="js/Highlight.js/highlight.pack.js" type="text/javascript"></script>
        <script>hljs.initHighlightingOnLoad();</script>
    </head>

    <body id="top">
        <div id="main-wrap">
            <h1>Research Journal</h1>
            <h2 class="sub-h2"></h2>

            <div id="last-change">
                <p>Last changed: <time datetime="2015-06-09">July 20th, 2015</time></p>
            </div>

            <h2 id="toc">Table of Contents<a href="#toc" class="anchor-link"></a></h2>
            <ol>
                <li><a href="#conc-def">Concepts and Definitions</a>
                    <ol>
                        <li><a href="#def-ml">Definition: Machine Learning</a></li>
                        <li><a href="#def-dl">Definition: Deep Learning</a>
                            <ul>
                                <li><a href="#why-dl">Why Deep Learning?</a></li>
                            </ul>
                        </li>
                        <li><a href="#generative-models">Generative Models</a></li>
                        <li><a href="#discriminative-models">Discriminative Models</a></li>
                        <li><a href="#nlp">Natural Language Processing</a>
                            <ul>
                                <li><a href="#nlp-token">Token</a></li>
                                <li><a href="#ngram-model">n-gram Model</a></li>
                                <li><a href="#nlp-pos">Part of Speech</a></li>
                                <li><a href="#lex-hier">Organizing Words by Lexical Hierarchy</a></li>
                                <li><a href="#stemming">Stemming</a></li>
                                <li><a href="#bow">Bag of Words</a></li>
                                <li><a href="#tfidf">Term-frequency-inverse Document Frequency</a></li>
                            </ul>
                        </li>
                    </ol>
                </li>

                <li><a href="#papers">Papers</a>
                    <ul>
                        <li><a href="#week-1">Week 1</a>
                            <ol>
                                <li><a href="#emotions-from-text-tbep">Emotions from text: machine learning for text-based emotion prediction</a></li>
                                <li><a href="#ml-class-music-emo">Multi-Label Classification of Music into Emotions</a></li>
                            </ol>
                        </li>
                        <li><a href="#week-2">Week 2</a>
                            <ol>
                                <li><a href="#judging-movie-poster-dl">Judging a Movie by its Poster using Deep Learning</a></li>
                                <li><a href="#disamb-music-emo-sa">Disambiguating Music Emotion Using Software Agents</a></li>
                            </ol>
                        </li>
                        <li><a href="#week-4">Week 4</a>
                            <ol>
                                <li><a href="#dl-mlc">Deep Learning for Multi-Label Classification</a></li>
                            </ol>
                        </li>
                    </ul>
                </li>
                <li><a href="#footnotes">Footnotes</a></li>
                <li><a href="#references">References</a></li>
            </ol>

            <h2 id="conc-def">Concepts and Definitions</h2>

            <h3 id="def-ml">Definition: Machine Learning<a class="anchor-link" href="#def-ml"></a></h3>
            »A computer program is said to learn from experimence E with respect
            to some class of tasks T and performance measure P, if its performance at
            tasks in T , as measured by P, improves with experience E.« — Mitchell, 1997<sup><a href="#footnote1">[1]</a></sup>
            <h3 id="def-dl">Definition: Deep Learning</h3>
            <h4 id="why-dl">Why Deep Learning?</h4>
            <p>Although <em>Shallow Neural Networks</em> (traditional Neural Networks with
            <em>one or two</em><sup>citation needed</sup> hidden layers)
            work ok for most models, more hidden layers
            result in better results. The problem is that the backpropagation
            algorithm does not work well on randomly initialized <em>Deep Neural
            Networks</em> (Neural Networks with more than <em>two</em><sup>citation needed</sup>
            hidden layers)
            because it might get stuck in local minima and thus result
            in poor solutions.
            <sup><a href="#footnote2">[2]</a></sup></p>

            <p>In contrast to shallow Neural Nets, Deep Neural Networks allow for
            learning on hierarchical models that provide a progression from high level
            to low level complexity, and thus refining the representation with each hidden
            layer representing a level of abstraction.<sup>citation needed</sup></p>

            <h3 id="generative-models">Generative Models<a class="anchor-link" href="#generative-models"></a></h3>
            <p><em>Generative Models</em> are Machine Learning models that yield an
            alternative representation of the input data. They represent an alternative
            view on the data that might improve the learning because it improves the
            feature space (for example it fits the feature space better to the
            desired output).<sup>citation needed</sup>


            <h3 id="discriminative-models">Discriminative Models<a class="anchor-link" href="#discriminative-models"></a></h3>
            <p>TODO</p>

            <h3 id="nlp">Natural Language Processing<a class="anchor-link" href="#nlp"></a></h3>
            <h4 id="nlp-token">Token<a class="anchor-link" href="#nlp-token"></a></h4>
            <p><em>Token</em> means the individual occurences of something. A Token
            has an associated <em>Type</em>.<sup><a href="#ref1">[MS99, P. 22]</a></sup></p>
            <p>Splitting texts into Tokens is thus referred to as <em>Tokenization</em>
            or <em>Tokenizing</em></p>

            <h4 id="ngram-model">n-gram Model<a class="anchor-link" href="#ngram-model"></a></h4>
            <p>The <em>n-gram Model</em> is basically just a Markov Chain modelling
            the assumption that a probability of a word in a text only depends
            on the previous $k$ words.<sup><a href="#ref1">[MS99, P. 77]</a></sup></p>
            <p>See also <a href="#ref7">[RuNorv14]</a> for a more detailed explanation.</p>

            <h4 id="nlp-pos">Parts of Speech (POS)<a class="anchor-link" href="#nlp-pos"></a></h4>
            <p><em>Parts of Speech (POS)</em> refers to classes of words
            which show syntactically similar behavior, often a semantic type. Examples
            are Nouns and Adjectives. An easy way to test words for a given class
            is the <em>Substition Test</em>, which consists of replacing a word of the same
            (assumed) class in a sentence.</p>
            <p>Each of these POS classes have associated <em>Parts of Speech Tags</em>
            which really are just abbreviations of the class.
            <sup><a href="#ref1">[MS99, P. 81f]</a></sup></p>

            <h4 id="lex-hier">Organizing Words by Lexical Hiearchy<a href="#lex-hier" class="anchor-link"></a></h4>
            <ul>
                <li><strong>hypernymy:</strong> more general word (<em>animal</em> is a hypernym of cat)</li>
                <li><strong>hyponymy:</strong> more specific word (<em>cat</em> is a hyponym of animal)</li>
                <li><strong>antonymy:</strong> opposite meaning word (<em>cold</em> and <em>hot</em> are antonyms)</li>
                <li><strong>meronymy:</strong> part-whole relationship (<em>tyre</em> is a meronym of car)</li>
                <li><strong>holonymy:</strong> the whole corresponding to a part (<em>car</em> is a holonym to tyre)</li>
                <li><strong>synonym:</strong> words with (almost) the same meaning</li>
                <li><strong>homonyms:</strong> words that are written the same way but mean different things</li>
                <li><strong>polyseme:</strong> word’s meaning/senses are related (<em>branch</em> as part of a leaf, part of a company)</li>
                <li><strong>ambiguity:</strong> polyseme or homonym</li>
                <li><strong>homophony:</strong> homonym that is pronounced the same way</li>
            </ul>
            <p>See <a href="#ref1">[MS99, P. 77]</a>.</p>

            <h4 id="stemming">Stemming<a class="anchor-link" href="#stemming"></a></h4>
            <p>The process of removing affixes from words and thefore leaves
            only the stem of the word (for example <em>lied</em> and <em>lie</em>).
            <sup><a href="#ref1">[MSP99, P. 132]</a></sup></p>

            <h4 id="bow">Bag of Words<a class="anchor-link" href="#bow"></a></h4>
            <p><em>Bag of Words</em> is a listing of words with their corresponding
            wordcount. Each row represents a document, a column represents a word
            and a cell contains the wordcount.<sup>citation needed</sup></p>

            <h4 id="tfidf">Term-frequency-inverse Document Frequency<a class="anchor-link" href="#tfidf"></a></h4>
            <p><em>Term-frequency-inverse document frequency</em> associates weight to
            words and measures the relevance, and not the frequency, as opposed to
            <em>Bag of Words</em>.<sup>citation needed</sup></p>

            <h2 id="papers">Papers<a class="anchor-link" href="#papers"></a></h2>
            <h2 class="week-indicator" id="week-1">Week 1<a class="anchor-link" href="#week-1"></a></h2>

            <article>
                <h3 id="emotions-from-text-tbep">Emotions from text: machine learning for text-based emotion prediction<sup><a href="#footnote3"></a></sup><a class="anchor-link" href="#emotions-from-text-tbep"></a></h3>
                <div class="byline">
                    <address class="author">By <a rel="author">Cecilia Ovesdotter Alm</a>, <a rel="author">Dan Roth</a> and <a rel="author">Richard Sproat</a></address>
                </div>

                <div class="tags">
                    <ul>
                        <li>SNoW-Architecture</li>
                        <li>NLP</li>
                        <li>Text-to-Speech</li>
                    </ul>
                </div>

                <blockquote>
                    »In addition to information, text contains attitudinal, and more specifically, emotional
                    content. This paper explores the text-based emotion prediction problem empirically,
                    using supervised machine learning with the SNoW learning architecture. The goal is
                    to classify the emotional affinity of sentences in the narrative domain of children’s
                    fairy tales, for subsequent usage in appropriate expres-sive rendering of text-to-speech
                    synthesis. Initial experiments on a preliminary data set of 22 fairy tales show encouraging
                    results over a naive baseline and BOW approach for classification of emotional versus
                    non-emotional contents, with some dependency on parameter tuning. We also discuss results
                    for a tripartite model which covers emotional valence, as well as feature set alternations.
                    In addition, we present plans for a more cognitively sound sequential model, taking into
                    consideration a larger set of basic emotions.«
                    <sup><a href="#ref2">[AlmRoSpo05]</a></sup>
                </blockquote>

                <h4>Notes</h4>
                <ul>
                    <li>I defenitely have to read more about word kinds like hyponyms, homonyms etc. to get a better understanding of the feature selection.</li>
                </ul>

                <h4>Further Action Items</h4>
                <ul>
                    <li>SNoW</li>
                    <li>Winnow Update Rule</li>
                    <li>10-fold cross validation</li>
                    <li>POS</li>
                    <li>Winnow Parameter Tuning</li>
                    <li>BOW</li>
                    <li>WordNET / synset</li>
                </ul>
            </article>

            <article>
                <h3 id="ml-class-music-emo">Multi-Label Classification of Music into Emotions<a class="anchor-link" href="#ml-class-music-emo"></a></h3>
                <div class="byline">
                    <address class="author">By <a rel="author">Konstantinos Trohidis</a>, <a rel="author">Grigorios Tsoumakas</a>, <a rel="author">George Kalliris</a> and <a rel="author">Ioannis P. Vlahavas</a></address>
                </div>

                <div class="tags">
                    <ul>
                        <li>Music Information Retrieval System</li>
                        <li>Support Vector Machine</li>
                        <li>Multi Label Classification</li>
                        <li>Binary Relevance Algorithm</li>
                        <li>k-Labelsets Algorithm</li>
                        <li>k-Nearest Neighbour Algorithm</li>
                        <li>Tellegen-Watson-Clark Model</li>
                    </ul>
                </div>

                <blockquote>
                    »In this paper, the automated detection of emotion in music is modeled as a multilabel
                    classification task, where a piece of music may belong to more than one class. Four
                    algorithms are evaluated and compared in this task. Furthermore, the predictive power
                    of several audio features is evaluated using a new multilabel feature selection method.
                    Experiments are conducted on a set of 593 songs with 6 clusters of music emotions based
                    on the Tellegen-Watson-Clark model. Results provide interesting insights into the quality
                    of the discussed algorithms and features.«
                    <sup><a href="#ref3">[TTKV08]</a></sup>
                </blockquote>

                <h4>Notes</h4>
                <ul>
                    <li>Good hints on previous/related work on the problem.</li>
                    <li>Introduces custom averaging with  label correlations (328).</li>
                    <li>States that clustering might be tricky due to semantic overlapping of moods.</li>
                </ul>

                <h4>Further Action Items</h4>
                <ul>
                    <li>Tellegen-Watson-Clark Emotion Model / PANAS</li>
                    <li>ML-kNN</li>
                    <li>attribute evaluation statistic / $\chi^2$ gain ratio</li>
                    <li>averaging methods: max/avg</li>
                    <li>gaussian mixture models</li>
                    <li>mutilabel feature ranking</li>
                    <li>music information retrieval system by emotion</li>
                </ul>
            </article>

            <h2 class="week-indicator" id="week-2">Week 2<a class="anchor-link" href="#week-2"></a></h2>
            <article>
                <h3 id="judging-movie-poster-dl">Judging a Movie by its Poster using Deep Learning<a class="anchor-link" href="#judging-movie-poster-dl"></a></h3>
                <div class="byline">
                    <address class="author">By <a rel="author">Brett Kuprel</a></address>
                </div>

                <div class="tags">
                    <ul>
                        <li>Deep Learning</li>
                        <li>Artificial Neural Networks</li>
                        <li>Gradient Descent</li>
                        <li>Auto-Encoders</li>
                        <li>Imdb</li>
                    </ul>
                </div>

                <blockquote>
                    »It is often the case that a human can de-termine the genre of a movie by looking at its
                    movie poster. This task is not trivial for computers. A recent advance in machine learning
                    called deep learning allows algorithms to learn important features from large datasets.
                    Rather than analyzing an image pixel by pixel, for example, higher level features can be
                    used for classication. In this project I attempted to train a neural network of stacked
                    autoencoders to predict a movie's genre given an image of its movie poster. My hypothesis
                    is that a good algorithm can correctly guess the genre based on the movie poster at least
                    half the time.«
                    <sup><a href="#ref4">[Kuprel]</a></sup>
                </blockquote>

                <h4>Notes</h4>
                <ul>
                    <li>Good hint on future work on the problem</li>
                </ul>

                <h4>Further Action Items</h4>
                <ul>
                    <li>Theano (with example stacked auto-encoders)</li>
                    <li>argmax</li>
                    <li>diffusion of gradients</li>
                    <li>curse of dimensionality</li>
                </ul>
            </article>

            <article>
                <h3 id="disamb-music-emo-sa">Disambiguating Music Emotion Using Software Agents<a class="anchor-link" href="#disamb-music-emo-sa"></a></h3>

                <div class="byline">
                    <address class="author">By <a rel="author">Dan Yang</a> and <a rel="author">Won-Sook Lee</a></address>
                </div>

                <div class="tags">
                    <ul>
                        <li>Support Vector Machine</li>
                        <li>Weka</li>
                        <li>Rainbow Text Mining</li>
                        <li>Tellegen-Watson-Clark</li>
                        <li>Verbal Emotion Identification</li>
                    </ul>
                </div>

                <blockquote>
                    »Annotating music poses a cognitive load on listeners and this potentially interferes with
                    the emotions being reported. One solution is to let software agents learn to make  the
                    annotator’s task easier and more efficient. Emo is a music annotation prototype that
                    combines inputs from both human and software agents to better study human listening. A
                    compositional  theory of musical meaning provides the overall heuristics for the annotation
                    process,  with the listener drawing upon different influences such as acoustics, lyrics and
                    cultural metadata to focus on a specific musical mood. Software agents track the way these
                    choices are made from the influences  available. A functional theory of human emotion
                    provides the basis for introducing necessary  bias into the machine learning agents.
                    Conflicting positive and negative emotions can be separated on the basis of their different
                    function (reward-approach and threat-avoidance) or dysfunction (psychotic). Negative
                    emotions have strong ambiguity and these are the focus of the experiment. The results
                    of mining psychological features of lyrics are promising, recognisable in terms of common
                    sense ideas of emotion and in terms of accuracy. Further ideas for deploying agents in this
                    model of music annotation are presented.«
                    <sup><a href="#ref5">[YanLee04]</a></sup>
                </blockquote>

                <h4>Notes</h4>
                <ul>
                    <li>States that future work could be done on graphical media</li>
                    <li>Weak dataset and pretty similar to [2]</li>
                    <li>Deploys simple »structured rating mode for embodyment in software agents to assist
                    human annotators«</li>
                    <li>Mentions semantic web and shared music ontologies</li>
                </ul>

                <h4>Further Action Items</h4>
                <ul>
                    <li>Baumann's Beagle System</li>
                    <li>Sum of Normed Fast Fourier Transformation (not relevant)</li>
                    <li>General Inquirer Package</li>
                    <li>Weka</li>
                    <li>Rainbow Text Mining</li>
                    <li>Verbal Emotion Identification</li>
                </ul>
            </article>

            <h2 class="week-indicator" id="week-4">Week 4<a class="anchor-link" href="#week-4"></a></h2>
            <article>
                <h3 id="dl-mlc">Deep Learning for Multi-label Classification<a class="anchor-link" href="#dl-mlc"></a></h3>
                <div class="byline">
                    <address class="author">
                        By <a rel="author">Jesse Read</a> and <a rel="author">Fernando Perez-Cruz</a>
                    </address>
                </div>

                <div class="tags">
                    <ul>
                        <li>Restricted Boltzmann Machine</li>
                        <li>Deep Learning</li>
                    </ul>
                </div>

                <blockquote>
                    »In multi-label classification, the main focus has been to develop
                    ways of learning the underlying dependencies between labels, and to
                    take advantage of this at classification time. Developing better
                    feature-space representations has been predominantly employed to
                    reduce complexity, e.g., by eliminating non-helpful feature attributes
                    from the input space prior to (or during) training. This is an
                    important task, since many multi-label methods typically create many
                    different copies or views of the same input data as they transform it,
                    and considerable memory can be saved by taking advantage of
                    redundancy. In this paper, we show that a proper development of the
                    feature space can make labels less interdependent and easier to model
                    and predict at inference time. For this task we use a deep learning
                    approach with restricted Boltzmann machines. We present a deep network
                    that, in an empirical evaluation, outperforms a number of competitive
                    methods from the literature.«
                    <sup><a href="#ref6">[ReaPe14]</a></sup>
                </blockquote>

                <h4>Notes</h4>
                <ul>
                    <li>Could become handy when it comes to references</li>
                    <li>Proposes that even if the abstract hidden variables represented
                    by the hidden layer do not necessarily correspond directly to given
                    labels we can expect better performance by using the hidden space</li>

                </ul>

                <h4>Further Action Items</h4>
                <ul>
                    <li>Finish reading</li>
                </ul>
            </article>

            <h2 id="appendix">Appendix<a class="anchor-link" href="#appendix"></a></h2>
            <h3 id="footnotes">Footnotes<a class="anchor-link" href="#footnotes"></a></h3>

            <ol>
                <li id="footnote1">Mitchell, Tom E.,»Machine Learning«, Published by McGraw-Hill, ISBN: 0070428077</li>
                <li id="footnote2">Bengio, Yoshua, Lamblin, Pascal, Popovici, Dan and Larochelle, Hugo, »Greedy Layer-Wise Training of Deep Networks«, NIPS, 2007</li>
            </ol>

            <h3 id="references">References<a class="anchor-link" href="#references"></a></h3>
            <ul>
                <li id="ref1"><strong>[MS99]:</strong> Foundations of Statistical Natural Language Processing, Manning, C. D.,
                Schütze, H. (ISBN: 0-262-13360-1)</li>
                <li id="ref2"><strong>[AlmRoSpo05]:</strong> <a href="http://l2r.cs.uiuc.edu/~danr/Papers/AlmRoSp05.pdf">Alm, Cecilia Ovesdotter, Roth, Dan, and Sproat, Richard . »Emotions from text: machine learning for text-based emotion prediction«. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP), 2005</a></li>
                <li id="ref3"><strong>[TTKV13]:</strong> <a href="http://ismir2008.ismir.net/papers/ISMIR2008_275.pdf">Trohidis, Konstantinos,
                    Tsoumakas, Grigorios,Kalliris, George and Vlahavas, Ioannis, »Multi-Label Classification of Music into Emotions«, EURASIP Journal on Audio, Speech, and Music Processing 2011</a></li>
                <li id="ref4"><strong>[Kuprel]:</strong> <a href="http://stanford.edu/~kuprel/cs221report.pdf">Kuprel, Brett, »Judging a Movie by its Poster using Deep Learning«</a></li>
                <li id="ref5"><strong>[YanLee04]:</strong> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.458.2901&rep=rep1&type=pdf">Yang, D. and Lee, W., »Disambiguating Music Emotion Using Software Agents«, In Proceedings of the 5th International Conference on Music Information Retrieval, 2004</a></li>
                <li id="ref6"><strong>[ReaPe14]:</strong> <a href="http://arxiv.org/pdf/1502.05988v1">Read, Jesse and Perez-Cruz, Fernando, »Deep Learning for Multi-label Classification«, 2014</a></li>
                <li id="ref7"><strong>[RuNorv14]:</strong> Russel, Stuart and Norvig, Peter, »Artificial Intelligence - A Modern Approach«, Pearson, ISBN 978129204202A</li>
            </ul>

            <footer class="main-foot">
                <ul>
                    <li><a href="#top">Back to top</a></li>
                    <li>&nbsp;</li>
                    <li>By Christian Schulze<br><a href="http://andinfinity.de">andinfinity.de</a></li>
                </ul>
            </footer>
        </div>
    </body>
</html>
